# Migration k8s-mono vers Ubuntu 24.04 + Kubernetes 1.32.4 + containerd

## ğŸ¯ Objectifs de la migration

- âœ… Base OS: CentOS 7 â†’ Ubuntu 24.04 LTS
- âœ… Kubernetes: 1.18.4 â†’ 1.32.4 (derniÃ¨re version stable)
- âœ… Runtime: Docker 19.03 â†’ containerd 1.7 (+ Docker CE optionnel)
- âœ… CNI: Flannel (version mise Ã  jour)
- âœ… CompatibilitÃ©: Maintien de toutes les fonctionnalitÃ©s PWD

## ğŸ“‹ Changements majeurs

### Runtime de conteneurs
```
AVANT (k8s 1.18 + CentOS 7):
- Docker 19.03.15 comme runtime
- dockershim intÃ©grÃ© dans kubelet
- VFS storage driver

APRÃˆS (k8s 1.32 + Ubuntu 24.04):
- containerd comme runtime principal
- Socket CRI: unix:///var/run/containerd/containerd.sock
- overlay2 storage driver
- Docker CE disponible pour docker-compose (optionnel)
```

### Configuration kubelet
```
CHANGEMENTS CLÃ‰S:
1. --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock
2. --cgroup-driver=systemd (au lieu de cgroupfs)
3. --network-plugin=cni (standard CNI)
4. Suppression de --pod-infra-container-image (gÃ©rÃ© par containerd)
```

### API Kubernetes
```
APIS CHANGÃ‰ES (1.18 â†’ 1.32):

DÃ‰PRÃ‰CIÃ‰ES/SUPPRIMÃ‰ES:
- extensions/v1beta1 â†’ networking.k8s.io/v1 (Ingress)
- rbac.authorization.k8s.io/v1beta1 â†’ v1
- apiextensions.k8s.io/v1beta1 â†’ v1

NOUVELLES:
- kubeadm.k8s.io/v1beta4 (API kubeadm)
- Ephemeral Containers (debug)
- Pod Security Standards
```

### Configuration kubeadm
```yaml
# AVANT (v1beta2 - k8s 1.18):
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration

# APRÃˆS (v1beta4 - k8s 1.32):
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
```

## ğŸ”§ Fichiers modifiÃ©s

### 1. Dockerfile
**Changements principaux:**
- `FROM centos:7` â†’ `FROM ubuntu:24.04`
- `yum install` â†’ `apt-get install`
- Repos Kubernetes mis Ã  jour (pkgs.k8s.io/core:/stable:/v1.32)
- Installation containerd + configuration SystemdCgroup
- Docker CE optionnel (pour docker-compose)

### 2. kubelet.env
**Nouveaux paramÃ¨tres:**
```bash
# Runtime endpoint pour containerd
KUBELET_RUNTIME_ARGS="--container-runtime-endpoint=unix:///var/run/containerd/containerd.sock"

# Cgroup driver systemd
KUBELET_CGROUP_ARGS="--cgroup-driver=systemd"

# Suppression de --pod-infra-container-image
```

### 3. kubelet.service
**Modifications:**
```ini
[Unit]
After=network-online.target containerd.service  # Ajout containerd

[Service]
Type=notify  # AjoutÃ© pour k8s 1.32
```

### 4. deploy-k8s.sh
**Nouvelles fonctionnalitÃ©s:**
- Configuration kubeadm v1beta4
- Skip kube-proxy pendant init (installÃ© manuellement aprÃ¨s)
- Configuration kube-proxy avec masquerade-all et conntrack=0
- Support containerd natif
- Flannel latest version

### 5. wrapkubeadm.sh
**Adaptations:**
- Support de l'API v1beta4
- Configuration token-auth via volumes
- Gestion moderne de kube-proxy (ConfigMap)
- Suppression des rÃ©fÃ©rences Ã  etcd2

### 6. systemctl (custom)
**ConservÃ© Ã  l'identique** - Fonctionne sur Ubuntu 24.04

### 7. daemon.json (Docker)
**Changements:**
```json
{
    "exec-opts": ["native.cgroupdriver=systemd"],  // Nouveau
    "storage-driver": "overlay2",                  // overlay2 au lieu de vfs
    "insecure-registries": ["127.0.0.1"],
    "hosts": ["unix:///var/run/docker.sock", "tcp://0.0.0.0:2375"]
}
```

### 8. Fichiers inchangÃ©s
- `tokens.csv` - âœ… Compatible
- `resolv.conf.override` - âœ… Compatible
- `motd` - âœ… Compatible

## ğŸš€ ProcÃ©dure de migration

### Ã‰tape 1: PrÃ©parer l'environnement

```bash
# Sur l'hÃ´te Ubuntu 24.04
sudo modprobe overlay
sudo modprobe br_netfilter
sudo modprobe xt_ipvs

# Rendre permanent
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
xt_ipvs
EOF

# Configuration sysctl
cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sudo sysctl --system

# Docker Swarm pour PWD
docker swarm init
```

### Ã‰tape 2: Organiser les fichiers

```bash
# Structure recommandÃ©e
dockerfiles/k8s-1.32-mono/
â”œâ”€â”€ Dockerfile              # Nouveau Dockerfile Ubuntu 24.04
â”œâ”€â”€ deploy-k8s.sh          # Script modernisÃ©
â”œâ”€â”€ kubelet.env            # Config kubelet pour containerd
â”œâ”€â”€ kubelet.service        # Service systemd kubelet
â”œâ”€â”€ wrapkubeadm.sh        # Wrapper kubeadm adaptÃ©
â”œâ”€â”€ systemctl             # Script custom (inchangÃ©)
â”œâ”€â”€ tokens.csv            # Tokens k8s (inchangÃ©)
â”œâ”€â”€ daemon.json           # Config Docker moderne
â”œâ”€â”€ resolv.conf.override  # Config DNS (inchangÃ©)
â””â”€â”€ motd                  # Message accueil (inchangÃ©)
```

### Ã‰tape 3: Build de l'image

```bash
cd dockerfiles/k8s-1.32-mono/

# Build
docker build -t k8s-mono:1.32-ubuntu24 .

# VÃ©rifier la taille
docker images k8s-mono:1.32-ubuntu24
```

### Ã‰tape 4: Tests

#### Test 1: DÃ©marrage basique
```bash
docker run --privileged --name k8s-test -d k8s-mono:1.32-ubuntu24

# Attendre 2-3 minutes
sleep 120

# VÃ©rifier les logs
docker logs k8s-test

# Se connecter
docker exec -it k8s-test bash
```

#### Test 2: VÃ©rifier k8s
```bash
# Dans le conteneur
kubectl get nodes
kubectl get pods -A
kubectl version

# VÃ©rifier containerd
systemctl status containerd
ctr version

# VÃ©rifier les pods systÃ¨me
kubectl get pods -n kube-system -o wide
```

#### Test 3: DÃ©ployer une application
```bash
# Test nginx
kubectl create deployment nginx --image=nginx:latest
kubectl expose deployment nginx --port=80 --type=NodePort
kubectl get svc

# Tester l'accÃ¨s
NODE_PORT=$(kubectl get svc nginx -o jsonpath='{.spec.ports[0].nodePort}')
curl http://localhost:$NODE_PORT

# Nettoyer
kubectl delete deployment nginx
kubectl delete service nginx
```

#### Test 4: IntÃ©gration PWD
```bash
# Tester dans l'environnement PWD complet
# 1. CrÃ©er plusieurs instances (3-5)
# 2. VÃ©rifier le rÃ©seau overlay
# 3. Tester la communication inter-instances
# 4. VÃ©rifier le port forwarding

# Depuis instance 1:
kubectl run test-pod --image=nginx --port=80
kubectl expose pod test-pod --type=NodePort

# Depuis instance 2:
INSTANCE1_IP=10.0.0.1  # IP de l'instance 1
curl http://$INSTANCE1_IP:<nodeport>
```

### Ã‰tape 5: DÃ©ploiement

```bash
# Tag pour votre registry
docker tag k8s-mono:1.32-ubuntu24 votre-registry/k8s-mono:1.32-ubuntu24
docker tag k8s-mono:1.32-ubuntu24 votre-registry/k8s-mono:latest

# Push
docker push votre-registry/k8s-mono:1.32-ubuntu24
docker push votre-registry/k8s-mono:latest

# Mettre Ã  jour la configuration PWD
# Modifier le fichier de config pour pointer vers la nouvelle image
```

## ğŸ› DÃ©pannage

### ProblÃ¨me: containerd ne dÃ©marre pas
```bash
# VÃ©rifier les logs
journalctl -u containerd -n 50

# VÃ©rifier la config
cat /etc/containerd/config.toml | grep SystemdCgroup
# Doit Ãªtre: SystemdCgroup = true

# RedÃ©marrer
systemctl restart containerd
```

### ProblÃ¨me: kubelet ne dÃ©marre pas
```bash
# VÃ©rifier les logs
journalctl -u kubelet -n 50

# VÃ©rifier le socket containerd
ls -la /var/run/containerd/containerd.sock

# VÃ©rifier les flags kubelet
cat /etc/systemd/system/kubelet.env
```

### ProblÃ¨me: Pods en Pending
```bash
# VÃ©rifier les events
kubectl get events --sort-by='.lastTimestamp'

# VÃ©rifier Flannel
kubectl get pods -n kube-flannel

# VÃ©rifier les routes
ip route show

# VÃ©rifier iptables
iptables -L -n -v -t nat | grep KUBE
```

### ProblÃ¨me: DNS ne fonctionne pas
```bash
# VÃ©rifier CoreDNS
kubectl get pods -n kube-system -l k8s-app=kube-dns

# Tester DNS
kubectl run -it --rm debug --image=busybox --restart=Never -- nslookup kubernetes.default

# VÃ©rifier resolv.conf
cat /etc/resolv.conf.override
```

### ProblÃ¨me: kube-proxy issues
```bash
# VÃ©rifier kube-proxy
kubectl get ds -n kube-system kube-proxy
kubectl logs -n kube-system -l k8s-app=kube-proxy

# RecrÃ©er kube-proxy
kubectl delete ds -n kube-system kube-proxy
# Puis relancer deploy-k8s.sh
```

## ğŸ“Š Comparaison des versions

| FonctionnalitÃ© | k8s 1.18 (ancien) | k8s 1.32 (nouveau) |
|----------------|-------------------|---------------------|
| **Runtime** | Docker 19.03 | containerd 1.7 |
| **Cgroup driver** | cgroupfs | systemd |
| **Storage driver** | vfs | overlay2 |
| **CNI** | Flannel 0.23 | Flannel latest |
| **kubeadm API** | v1beta2 | v1beta4 |
| **Support** | EOL (2020) | Actif jusqu'Ã  2025 |
| **SÃ©curitÃ©** | VulnÃ©rabilitÃ©s | Patches rÃ©cents |
| **Performance** | Bonne | Excellente |

## âœ… Checklist finale

Avant de dÃ©ployer en production:

- [ ] Build rÃ©ussi sans erreurs
- [ ] Image testÃ©e en local
- [ ] Cluster k8s dÃ©marre correctement
- [ ] Tous les pods systÃ¨me sont Running
- [ ] DÃ©ploiement d'app test rÃ©ussi
- [ ] RÃ©seau overlay PWD fonctionne
- [ ] Communication inter-instances OK
- [ ] Port forwarding testÃ©
- [ ] Tokens PWD fonctionnent
- [ ] DNS rÃ©solution OK
- [ ] Performances acceptables
- [ ] Logs clean (pas d'erreurs critiques)
- [ ] Documentation mise Ã  jour
- [ ] Plan de rollback prÃªt

## ğŸ”„ Plan de rollback

En cas de problÃ¨me:

```bash
# 1. Revenir Ã  l'ancienne image
docker pull votre-registry/k8s-mono:centos7-backup

# 2. Mettre Ã  jour la config PWD
# Pointer vers l'ancienne image

# 3. RedÃ©marrer les instances
# Les nouvelles instances utiliseront l'ancienne image

# 4. Investiguer les logs
# Identifier le problÃ¨me avant de retenter
```

## ğŸ“ˆ Prochaines Ã©tapes

AprÃ¨s migration rÃ©ussie:

1. **Monitoring**: Surveiller les mÃ©triques pendant 48h
2. **Documentation**: Mettre Ã  jour la doc utilisateur
3. **Formation**: Informer les utilisateurs des changements
4. **Optimisation**: Tuner les ressources si nÃ©cessaire
5. **Automatisation**: AmÃ©liorer les scripts de dÃ©ploiement

## ğŸ’¡ Bonnes pratiques

1. **Tests graduels**: Tester avec 1 instance, puis 3, puis 5
2. **FenÃªtre de maintenance**: Planifier une fenÃªtre de 2-4h
3. **Communication**: PrÃ©venir les utilisateurs Ã  l'avance
4. **Backup**: Garder l'ancienne image disponible 1 mois
5. **Monitoring**: Surveiller activement pendant la transition

---

**Version:** 1.0  
**Date:** 2025  
**Auteur:** Migration k8s 1.18 â†’ 1.32
